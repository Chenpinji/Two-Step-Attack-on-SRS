{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98125341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import wave as wav\n",
    "import os\n",
    "import librosa\n",
    "import soundfile\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "import tensorflow as tf\n",
    "import generate_masking_threshold as generate_mask\n",
    "import base64\n",
    "import hashlib\n",
    "import json \n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import scipy\n",
    "import random\n",
    "#import scikits.audiolab\n",
    "\n",
    "def compute_mfcc(audio, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the MFCC for a given audio waveform. This is\n",
    "    identical to how DeepSpeech does it, but does it all in\n",
    "    TensorFlow so that we can differentiate through it.\n",
    "    \"\"\"\n",
    "    batch_size, size = audio.get_shape().as_list()\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "\n",
    "    # 1. Pre-emphasizer, a high-pass filter\n",
    "    audio = tf.concat(\n",
    "        (audio[:, :1], audio[:, 1:] - 0.97 * audio[:, :-1], np.zeros((batch_size, 512), dtype=np.float32)), 1)\n",
    "\n",
    "    # 2. windowing into frames of 512 samples, overlapping\n",
    "    windowed = tf.stack([audio[:, i:i + 512] for i in range(0, size - 320, 320)], 1)\n",
    "\n",
    "    window = np.hamming(512)\n",
    "    windowed = windowed * window\n",
    "\n",
    "    # 3. Take the FFT to convert to frequency space\n",
    "    ffted = tf.spectral.rfft(windowed, [512])\n",
    "    ffted = 1.0 / 512 * tf.square(tf.abs(ffted))\n",
    "\n",
    "    # 4. Compute the Mel windowing of the FFT\n",
    "    energy = tf.reduce_sum(ffted, axis=2) + np.finfo(float).eps\n",
    "    filters = np.load(\"filterbanks.npy\").T\n",
    "    feat = tf.matmul(ffted, np.array([filters] * batch_size, dtype=np.float32)) + np.finfo(float).eps\n",
    "\n",
    "    # 5. Take the DCT again, because why not\n",
    "    feat = tf.log(feat)\n",
    "    feat = tf.spectral.dct(feat, type=2, norm='ortho')[:, :, :26]\n",
    "\n",
    "    # 6. Amplify high frequencies for some reason\n",
    "    _, nframes, ncoeff = feat.get_shape().as_list()\n",
    "    n = np.arange(ncoeff)\n",
    "    lift = 1 + (22 / 2.) * np.sin(np.pi * n / 22)\n",
    "    feat = lift * feat\n",
    "    width = feat.get_shape().as_list()[1]\n",
    "\n",
    "    # 7. And now stick the energy next to the features\n",
    "    feat = tf.concat((tf.reshape(tf.log(energy), (-1, width, 1)), feat[:, :, 1:]), axis=2)\n",
    "    return feat\n",
    "\n",
    "def pad(mfcc2,mfcc1):\n",
    "    size1 = mfcc1.get_shape().as_list()\n",
    "    size2 = mfcc2.get_shape().as_list()\n",
    "    length = size1[1] - size2[1]\n",
    "    paddings = [[0,0],[0,length],[0,0]]\n",
    "    return tf.pad(mfcc2,paddings,\"CONSTANT\")\n",
    "\n",
    "def SNR(origanl, current):\n",
    "    noise=current-origanl\n",
    "    origanl_ar = sess.run(origanl)\n",
    "    noise_ar = sess.run(noise)\n",
    "    ans = 20*np.log10(np.linalg.norm(origanl_ar, ord=2)/np.linalg.norm(noise_ar, ord=2))\n",
    "    return ans\n",
    "\n",
    "def new_input(noise, audio_sequence1):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tensor = tf.clip_by_value(noise+audio_sequence1, -2**15, 2**15-1)\n",
    "        array = sess.run(tensor)\n",
    "    return array\n",
    "\n",
    "def psychoacoustic_loss(adv_audio, original, psd_max_a, th):\n",
    "    logits_delta = transform((adv_audio[0,:] - original[0,:]),psd_max_a[0])\n",
    "    psychoacoustic_loss = tf.reduce_mean(tf.nn.relu(logits_delta - th[0]))\n",
    "    return psychoacoustic_loss\n",
    "\n",
    "def truncate(mfcc1, mfcc2):\n",
    "    size1 = mfcc1.get_shape().as_list()#origin\n",
    "    #size2 = mfcc2.get_shape().as_list()#target\n",
    "    mfcc2 = tf.slice(mfcc2,[0,0,0],[1,size1[1],26])\n",
    "    return mfcc2\n",
    "\n",
    "def loss(original, target, noise, psychoacoustic_loss,alpha):\n",
    "    mfcc1 = compute_mfcc(original + noise)\n",
    "    size1 = original.get_shape().as_list()\n",
    "    size2 = target.get_shape().as_list()\n",
    "    if size1[1] > size2[1]:\n",
    "        mfcc2 = pad(compute_mfcc(target),mfcc1)\n",
    "    else:\n",
    "        mfcc2 = truncate(mfcc1,compute_mfcc(target))\n",
    "    loss = tf.norm(mfcc1-mfcc2,2) + alpha * psychoacoustic_loss\n",
    "    #+ 0.01 * tf.cast(tf.norm(noise,2),dtype = tf.float32)\n",
    "#     loss =  tf.norm(cal_mfcc(new_input(noise, audio_sequence1),sample_rate1) \n",
    "#     - pad(cal_mfcc(audio_sequence2, sample_rate2)),2) + 0.001 * tf.cast(tf.norm(noise, 2),dtype = tf.float64)\n",
    "    return loss\n",
    "    \n",
    "def getSign(timestamp, nonce):\n",
    "    hs = hashlib.sha256()\n",
    "    appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "    secret = '3c8a61e2bdb0ee2d0af74814142ba2ee'\n",
    "    hs.update((appkey + timestamp + secret + nonce).encode('utf-8'))\n",
    "    signature = hs.hexdigest().upper()\n",
    "    return signature\n",
    "def identifyFeatureByGroupId(confirmFeatureFileName):\n",
    "    identify_feature = open(confirmFeatureFileName, 'rb').read()\n",
    "    # 声纹base64字符串\n",
    "    audio_data = base64.b64encode(identify_feature)\n",
    "    timestamp = str(int(time.time() * 1000))\n",
    "    nonce = str(uuid.uuid1()).replace('-', '')\n",
    "    sign = getSign(timestamp, nonce)\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "    groupId = '12'\n",
    "    host = 'https://ai-vpr.hivoice.cn'\n",
    "    identifyFeatureByGroupIdEndPoint = '/vpr/v1/identifyFeatureByGroupId'\n",
    "    identify_feature_param = {\n",
    "        \"appkey\": appkey,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"nonce\": nonce,\n",
    "        \"sign\": sign,\n",
    "        \"groupId\": groupId,\n",
    "        \"topN\": 6,\n",
    "        \"audioData\": audio_data.decode(),\n",
    "        \"audioSampleRate\": 16000,\n",
    "        \"audioFormat\": \"wav\"\n",
    "    }\n",
    "    #print('identify_feature_param', identify_feature_param)\n",
    "    identify_feature_resp = requests.post(url=host + identifyFeatureByGroupIdEndPoint,\n",
    "                                          data=json.dumps(identify_feature_param),\n",
    "                                          headers=headers)\n",
    "    identify_feature_result = json.loads(identify_feature_resp.content)\n",
    "    return identify_feature_result['data'][0]['featureInfo'], identify_feature_result['data'][0]['score'],identify_feature_result['data'][1]['featureInfo'], identify_feature_result['data'][1]['score']\n",
    "\n",
    "\n",
    "class Transform(object):\n",
    "    '''\n",
    "    Return: PSD\n",
    "    '''\n",
    "    def __init__(self, window_size):\n",
    "        self.scale = 8. / 3.\n",
    "        self.frame_length = int(window_size)\n",
    "        self.frame_step = int(window_size // 4)\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __call__(self, x, psd_max_ori):\n",
    "        win = tf.contrib.signal.stft(x, self.frame_length, self.frame_step)\n",
    "        z = self.scale * tf.abs(win / self.window_size)\n",
    "        psd = tf.square(z)\n",
    "        PSD = tf.pow(10., 9.6) / tf.reshape(psd_max_ori, [-1, 1, 1]) * psd\n",
    "        return PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e4e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "0\n",
      "current loss: 920.5245 SNR: 37.118709087371826\n",
      "current psychoacoustic_loss 860.05023\n",
      "100\n",
      "current loss: 694.377 SNR: 30.698511600494385\n",
      "current psychoacoustic_loss 4829.8394\n",
      "200\n",
      "current loss: 635.0102 SNR: 26.755526065826416\n",
      "current psychoacoustic_loss 12508.816\n",
      "300\n",
      "current loss: 599.88226 SNR: 24.19147491455078\n",
      "current psychoacoustic_loss 22863.82\n",
      "400\n",
      "current loss: 572.66626 SNR: 22.268283367156982\n",
      "current psychoacoustic_loss 35686.766\n",
      "500\n",
      "current loss: 550.5837 SNR: 20.72648525238037\n",
      "current psychoacoustic_loss 50686.473\n",
      "600\n",
      "current loss: 531.6199 SNR: 19.44007158279419\n",
      "current psychoacoustic_loss 67237.99\n",
      "700\n",
      "current loss: 513.31714 SNR: 18.3423912525177\n",
      "current psychoacoustic_loss 85325.23\n",
      "800\n",
      "current loss: 497.18317 SNR: 17.37626552581787\n",
      "current psychoacoustic_loss 105054.09\n",
      "900\n",
      "current loss: 481.20963 SNR: 16.496570110321045\n",
      "current psychoacoustic_loss 126585.984\n",
      "932\n",
      "current loss: 475.79422 SNR: 16.230891942977905\n",
      "current psychoacoustic_loss 133794.33\n",
      "0\n",
      "current loss: 987.6355 SNR: 36.51158094406128\n",
      "current psychoacoustic_loss 706.45746\n",
      "100\n",
      "current loss: 753.1443 SNR: 29.57390785217285\n",
      "current psychoacoustic_loss 5979.787\n",
      "200\n",
      "current loss: 677.9295 SNR: 25.44503927230835\n",
      "current psychoacoustic_loss 17215.078\n",
      "300\n",
      "current loss: 630.38763 SNR: 22.7780818939209\n",
      "current psychoacoustic_loss 33786.24\n",
      "400\n",
      "current loss: 595.0323 SNR: 20.824949741363525\n",
      "current psychoacoustic_loss 55001.305\n",
      "500\n",
      "current loss: 566.3322 SNR: 19.28313136100769\n",
      "current psychoacoustic_loss 80050.4\n",
      "600\n",
      "current loss: 542.0549 SNR: 18.003129959106445\n",
      "current psychoacoustic_loss 108664.37\n",
      "700\n",
      "current loss: 519.4112 SNR: 16.908820867538452\n",
      "current psychoacoustic_loss 140254.69\n",
      "800\n",
      "current loss: 499.6344 SNR: 15.961623191833496\n",
      "current psychoacoustic_loss 175218.14\n",
      "900\n",
      "current loss: 481.85754 SNR: 15.127335786819458\n",
      "current psychoacoustic_loss 213271.28\n",
      "927\n",
      "current loss: 477.30954 SNR: 14.917449951171875\n",
      "current psychoacoustic_loss 223983.61\n",
      "0\n",
      "current loss: 1142.9873 SNR: 39.236345291137695\n",
      "current psychoacoustic_loss 244.39006\n",
      "100\n",
      "current loss: 883.5937 SNR: 32.03620910644531\n",
      "current psychoacoustic_loss 1657.4164\n",
      "200\n",
      "current loss: 787.951 SNR: 27.697181701660156\n",
      "current psychoacoustic_loss 5295.445\n",
      "300\n",
      "current loss: 726.5608 SNR: 24.9640154838562\n",
      "current psychoacoustic_loss 11083.25\n",
      "400\n",
      "current loss: 682.22595 SNR: 23.00410032272339\n",
      "current psychoacoustic_loss 18486.645\n",
      "500\n",
      "current loss: 646.39685 SNR: 21.46672487258911\n",
      "current psychoacoustic_loss 27339.74\n",
      "600\n",
      "current loss: 617.64496 SNR: 20.206434726715088\n",
      "current psychoacoustic_loss 37373.33\n",
      "700\n",
      "current loss: 592.0 SNR: 19.135425090789795\n",
      "current psychoacoustic_loss 48462.227\n",
      "800\n",
      "current loss: 569.8042 SNR: 18.200206756591797\n",
      "current psychoacoustic_loss 60673.094\n",
      "802\n",
      "current loss: 569.353 SNR: 18.182653188705444\n",
      "current psychoacoustic_loss 60928.58\n",
      "0\n",
      "current loss: 1180.6456 SNR: 36.63266897201538\n",
      "current psychoacoustic_loss 551.6495\n",
      "100\n",
      "current loss: 871.67334 SNR: 30.02368927001953\n",
      "current psychoacoustic_loss 2555.0068\n",
      "200\n",
      "current loss: 773.3748 SNR: 25.79066276550293\n",
      "current psychoacoustic_loss 7679.0635\n",
      "300\n",
      "current loss: 711.38257 SNR: 23.09788465499878\n",
      "current psychoacoustic_loss 15680.212\n",
      "400\n",
      "current loss: 665.6053 SNR: 21.16569995880127\n",
      "current psychoacoustic_loss 25910.186\n",
      "500\n",
      "current loss: 629.4078 SNR: 19.655848741531372\n",
      "current psychoacoustic_loss 38098.55\n",
      "579\n",
      "current loss: 604.6898 SNR: 18.657397031784058\n",
      "current psychoacoustic_loss 49018.555\n",
      "0\n",
      "current loss: 884.34766 SNR: 39.6464204788208\n",
      "current psychoacoustic_loss 229.19904\n",
      "100\n",
      "current loss: 625.0497 SNR: 33.01048994064331\n",
      "current psychoacoustic_loss 1241.5807\n",
      "200\n",
      "current loss: 557.82684 SNR: 28.98966073989868\n",
      "current psychoacoustic_loss 3319.197\n",
      "300\n",
      "current loss: 520.9997 SNR: 26.423113346099854\n",
      "current psychoacoustic_loss 6286.8438\n",
      "400\n",
      "current loss: 493.74554 SNR: 24.53193187713623\n",
      "current psychoacoustic_loss 10091.766\n",
      "500\n",
      "current loss: 471.28543 SNR: 23.03156614303589\n",
      "current psychoacoustic_loss 14699.851\n",
      "584\n",
      "current loss: 454.56284 SNR: 21.972219944000244\n",
      "current psychoacoustic_loss 19058.564\n",
      "0\n",
      "current loss: 1046.5383 SNR: 32.23468065261841\n",
      "current psychoacoustic_loss 1947.2106\n",
      "100\n",
      "current loss: 704.62067 SNR: 27.23374843597412\n",
      "current psychoacoustic_loss 5199.9927\n",
      "200\n",
      "current loss: 619.37524 SNR: 23.33322286605835\n",
      "current psychoacoustic_loss 12510.536\n",
      "300\n",
      "current loss: 566.84283 SNR: 20.76343059539795\n",
      "current psychoacoustic_loss 22940.281\n",
      "400\n",
      "current loss: 529.6413 SNR: 18.890442848205566\n",
      "current psychoacoustic_loss 36119.914\n",
      "500\n",
      "current loss: 501.32852 SNR: 17.44375467300415\n",
      "current psychoacoustic_loss 51175.82\n",
      "600\n",
      "current loss: 477.50052 SNR: 16.25502109527588\n",
      "current psychoacoustic_loss 67984.6\n",
      "612\n",
      "current loss: 474.42593 SNR: 16.124837398529053\n",
      "current psychoacoustic_loss 70126.95\n",
      "0\n",
      "current loss: 1080.8562 SNR: 38.905813694000244\n",
      "current psychoacoustic_loss 403.82422\n",
      "100\n",
      "current loss: 823.79895 SNR: 31.9750714302063\n",
      "current psychoacoustic_loss 2406.9385\n",
      "200\n",
      "current loss: 743.3881 SNR: 27.816174030303955\n",
      "current psychoacoustic_loss 6656.555\n",
      "300\n",
      "current loss: 693.92523 SNR: 25.13118267059326\n",
      "current psychoacoustic_loss 13880.4375\n",
      "400\n",
      "current loss: 657.88763 SNR: 23.186018466949463\n",
      "current psychoacoustic_loss 23485.977\n",
      "500\n",
      "current loss: 629.1885 SNR: 21.65937900543213\n",
      "current psychoacoustic_loss 35075.598\n",
      "600\n",
      "current loss: 605.02716 SNR: 20.401952266693115\n",
      "current psychoacoustic_loss 48493.855\n",
      "700\n",
      "current loss: 584.189 SNR: 19.333395957946777\n",
      "current psychoacoustic_loss 63531.617\n",
      "800\n",
      "current loss: 566.42957 SNR: 18.40791344642639\n",
      "current psychoacoustic_loss 80007.77\n",
      "889\n",
      "current loss: 551.69977 SNR: 17.679163217544556\n",
      "current psychoacoustic_loss 95669.945\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92e49a8320a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mselect3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_teacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNewInput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsychoacoustic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsd_max_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsychoacoustic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsd_max_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"/mnt/data/Chenpinji/cmu_dataset\"\n",
    "filename2 = '/mnt/data/Chenpinji/cmu_dataset/cmu7/wav/arctic_a0008.wav'\n",
    "for cnt in range(1000):\n",
    "    select = random.randint(0,9)\n",
    "    select2 = random.randint(0,500)\n",
    "    filename_1 = path + '/' + os.listdir(path)[select] + '/' + 'wav'\n",
    "    audioname = os.listdir(filename_1)[select2]\n",
    "    filename1 = filename_1 + '/'+audioname\n",
    "    sample_rate1, audio_sequence1 = wf.read(filename1)\n",
    "    sample_rate2, audio_sequence2 = wf.read(filename2)\n",
    "    #time = a1 / f1#音频时长\n",
    "    audio1 = np.expand_dims(audio_sequence1,0)\n",
    "    audio2 = np.expand_dims(audio_sequence2,0)\n",
    "    len1 = len(audio1[0])\n",
    "    len2 = len(audio2[0])\n",
    "    th, psd_max = generate_mask.generate_th(audio_sequence1.astype(float), 16000, 2048)\n",
    "    th=np.expand_dims(th,0)\n",
    "    psd_max=np.expand_dims(psd_max,0)\n",
    "    transform = Transform(2048)\n",
    "    psd_max_a = tf.cast(psd_max, tf.float32)\n",
    "\n",
    "    #stage 1, nearly no constraint on noise size, which aims to make the attack succeed\n",
    "    original = tf.Variable(np.zeros((1, len1), dtype=np.float32))\n",
    "    target  = tf.Variable(np.zeros((1, len2), dtype=np.float32))\n",
    "    with tf.variable_scope(\"noise\"):\n",
    "        noise=tf.Variable(tf.random_normal([1,len1],stddev = 50))\n",
    "        #noise=tf.clip_by_value(noise,-5000,5000)\n",
    "        t_vars = tf.trainable_variables()\n",
    "        noise_vars = [var for var in t_vars if \"noise\" in var.name]\n",
    "    #config = tf.ConfigProto(device_count = {'CPU': 4})\n",
    "    with tf.Session() as sess:\n",
    "        train_teacher = tf.train.AdamOptimizer(2).minimize (loss(original, target, noise, psychoacoustic_loss(original + noise, original, psd_max_a, th),0.00001), var_list=noise_vars)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        original = original.assign(np.array(audio1))\n",
    "        target   = target.assign(np.array(audio2))\n",
    "        select3 = random.randint(500,1000)\n",
    "        for i in range(select3): \n",
    "            sess.run((train_teacher))\n",
    "            if i % 100 == 0:\n",
    "                a,b,NewInput= sess.run([loss(original, target, noise, psychoacoustic_loss(original + noise, original, psd_max_a, th), 0.00001),psychoacoustic_loss(original + noise, original, psd_max_a, th), original + noise])\n",
    "                print(i)\n",
    "                print('current loss:',a,'SNR:',SNR(original, NewInput))\n",
    "                print('current psychoacoustic_loss', b)\n",
    "            if i == select3 - 1:\n",
    "                a,b,NewInput= sess.run([loss(original, target, noise, psychoacoustic_loss(original + noise, original, psd_max_a, th), 0.00001),psychoacoustic_loss(original + noise, original, psd_max_a, th), original + noise])\n",
    "                print(i)\n",
    "                print('current loss:',a,'SNR:',SNR(original, NewInput))\n",
    "                print('current psychoacoustic_loss', b)\n",
    "                audio_name = '/mnt/data/Chenpinji/mfcc_Gen1000/'+'mfccGen_'+str(cnt+193) + '.wav'\n",
    "                scaled = np.array(np.clip(np.round(NewInput[0]),-2 ** 15, 2 ** 15 - 1),dtype = np.int16)\n",
    "                wf.write(audio_name, 16000 ,scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (default, Mar 27 2019, 22:11:17) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
