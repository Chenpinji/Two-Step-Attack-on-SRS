{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import scipy.io.wavfile as wf\n",
    "import numpy as np\n",
    "import base64\n",
    "import hashlib\n",
    "import json \n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import scipy\n",
    "import random\n",
    "import hmac\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from urllib.parse import urlencode\n",
    "from wsgiref.handlers import format_date_time\n",
    "from pydub import AudioSegment\n",
    "import talentedsoft\n",
    "#import scikits.audiolab\n",
    "##科大讯飞声纹识别 tjs's \n",
    "APPId = \"fcfefe42\"\n",
    "APISecret = \"NmE5NTZkNzFlMzg3MGM0ZDBmZTdkODYx\"\n",
    "APIKey = \"aba4d1c2815577b411d5d5a4966796aa\"\n",
    "class Gen_req_url(object):\n",
    "    \"\"\"生成请求的url\"\"\"\n",
    "\n",
    "    def sha256base64(self, data):\n",
    "        sha256 = hashlib.sha256()\n",
    "        sha256.update(data)\n",
    "        digest = base64.b64encode(sha256.digest()).decode(encoding='utf-8')\n",
    "        return digest\n",
    "\n",
    "    def parse_url(self, requset_url):\n",
    "        stidx = requset_url.index(\"://\")\n",
    "        host = requset_url[stidx + 3:]\n",
    "        # self.schema = requset_url[:stidx + 3]\n",
    "        edidx = host.index(\"/\")\n",
    "        if edidx <= 0:\n",
    "            raise Exception(\"invalid request url:\" + requset_url)\n",
    "        self.path = host[edidx:]\n",
    "        self.host = host[:edidx]\n",
    "\n",
    "    # build websocket auth request url\n",
    "    def assemble_ws_auth_url(self, requset_url, api_key, api_secret, method=\"GET\"):\n",
    "        self.parse_url(requset_url)\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "        # date = \"Thu, 12 Dec 2019 01:57:27 GMT\"\n",
    "        signature_origin = \"host: {}\\ndate: {}\\n{} {} HTTP/1.1\".format(self.host, date, method, self.path)\n",
    "        signature_sha = hmac.new(api_secret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "        signature_sha = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "        authorization_origin = \"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\" % (\n",
    "            api_key, \"hmac-sha256\", \"host date request-line\", signature_sha)\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "        values = {\n",
    "            \"host\": self.host,\n",
    "            \"date\": date,\n",
    "            \"authorization\": authorization\n",
    "        }\n",
    "\n",
    "        return requset_url + \"?\" + urlencode(values)\n",
    "\n",
    "\n",
    "def gen_req_body(apiname, APPId, file_path=None):\n",
    "    \"\"\"\n",
    "    生成请求的body\n",
    "    :param apiname\n",
    "    :param APPId: Appid\n",
    "    :param file_name:  文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if apiname == 'createFeature':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"createFeature\",\n",
    "                    \"groupId\": \"102\",\n",
    "                    \"featureId\": \"cmu_scottish\",\n",
    "                    \"featureInfo\": \"wav08\",\n",
    "                    \"createFeatureRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'createGroup':\n",
    "\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"createGroup\",\n",
    "                    \"groupId\": \"102\",\n",
    "                    \"groupName\": \"cmu_dataset\",\n",
    "                    \"groupInfo\": \"cmu_dataset\",\n",
    "                    \"createGroupRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "   \n",
    "    elif apiname == 'queryFeatureList':\n",
    "\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"queryFeatureList\",\n",
    "                    \"groupId\": \"102\",\n",
    "                    \"queryFeatureListRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'searchFea':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"searchFea\",\n",
    "                    \"groupId\": \"102\",\n",
    "                    \"topK\": 10,\n",
    "                    \"searchFeaRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'searchScoreFea':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"searchScoreFea\",\n",
    "                    \"groupId\": \"iFLYTEK_examples_groupId\",\n",
    "                    \"dstFeatureId\": \"p374\",\n",
    "                    \"searchScoreFeaRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"输入的apiname不在[createFeature, createGroup, deleteFeature, queryFeatureList, searchFea, searchScoreFea,updateFeature]内，请检查\")\n",
    "    return body\n",
    "\n",
    "def req_url(api_name, APPId, APIKey, APISecret, file_path=None):\n",
    "    \"\"\"\n",
    "    开始请求\n",
    "    :param APPId: APPID\n",
    "    :param APIKey:  APIKEY\n",
    "    :param APISecret: APISecret\n",
    "    :param file_path: body里的文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gen_req_url = Gen_req_url()\n",
    "    body = gen_req_body(apiname=api_name, APPId=APPId, file_path=file_path)\n",
    "    request_url = gen_req_url.assemble_ws_auth_url(requset_url='https://api.xf-yun.com/v1/private/s782b4996', method=\"POST\", api_key=APIKey, api_secret=APISecret)\n",
    "    headers = {'content-type': \"application/json\", 'host': 'api.xf-yun.com', 'appid': '$APPID'}\n",
    "    response = requests.post(request_url, data=json.dumps(body), headers=headers)\n",
    "    tempResult = json.loads(response.content.decode('utf-8'))\n",
    "    #print(tempResult)\n",
    "    #print(base64.b64decode(tempResult['payload'][api_name + 'Res']['text']))\n",
    "\"\"\"\n",
    " * 1.声纹识别接口,请填写在讯飞开放平台-控制台-对应能力页面获取的APPID、APIKey、APISecret\n",
    " * 2.groupId要先创建,然后再在createFeature里使用,不然会报错23005,修改时需要注意保持统一\n",
    " * 3.音频base64编码后数据(不超过4M),音频格式需要16K、16BIT的MP3音频。\n",
    " * 4.主函数只提供调用示例,其他参数请到对应类去更改,以适应实际的应用场景。\n",
    "\"\"\"\n",
    "def req_score(api_name, APPId,  APIKey, APISecret, file_path=None):\n",
    "    gen_req_url = Gen_req_url()\n",
    "    body = gen_req_body(apiname=api_name, APPId=APPId, file_path=file_path)\n",
    "    request_url = gen_req_url.assemble_ws_auth_url(requset_url='https://api.xf-yun.com/v1/private/s782b4996', method=\"POST\", api_key=APIKey, api_secret=APISecret)\n",
    "    headers = {'content-type': \"application/json\", 'host': 'api.xf-yun.com', 'appid': '$APPID'}\n",
    "    response = requests.post(request_url, data=json.dumps(body), headers=headers)\n",
    "    tempResult = json.loads(response.content.decode('utf-8'))\n",
    "    #print(tempResult)\n",
    "    return base64.b64decode(tempResult['payload'][api_name + 'Res']['text'])#,base64.b64decode(tempResult['payload'][api_name + 'Res']['text']['scoreList'][0]['score'])\n",
    "\n",
    "\n",
    "def GetSpeakerScore(speaker,value):\n",
    "    m = len(value)\n",
    "    result = ''\n",
    "    for i in range(0,m):\n",
    "        result+=chr(value[i]) #switch to string\n",
    "    result = eval(result)\n",
    "    v = list(result.values())[0]\n",
    "    #print(v)\n",
    "    lenv=len(v)\n",
    "    return v[0]['featureId'], v[0]['score'], v[1]['featureId'],v[1]['score']\n",
    "    # for i in range(lenv):\n",
    "    #     if(v[i]['featureId']==speaker):\n",
    "    #         return v[i]['score']\n",
    "\n",
    "#以上为Ifytyke\n",
    "#wav2mel = torch.jit.load(\"wav2mel.pt\")\n",
    "dvector = torch.jit.load(\"dvector-step250000.pt\").eval()\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "\n",
    "hop_length = 128\n",
    "n_mels = 40\n",
    "sample_rate = 16000\n",
    "\n",
    "def dvector_extraction(wav_tensor1):\n",
    "    #transform = torchaudio.transforms.MFCC(sample_rate = sample_rate,n_mfcc = 40, melkwargs={\"n_fft\": 1024, \"hop_length\": 128, \"n_mels\": 64, \"center\": False},)\n",
    "    transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=False,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=1,\n",
    "    norm='slaney',\n",
    "    onesided=True,\n",
    "    n_mels=n_mels,)\n",
    "    mel_tensor1 = transform(wav_tensor1).T\n",
    "    emb_tensor1 = dvector.embed_utterance(mel_tensor1)\n",
    "    return emb_tensor1\n",
    "def SNR(wav_tensor1, noise_tensor):\n",
    "    temp1 = wav_tensor1\n",
    "    temp2 = noise_tensor\n",
    "    temp2 = temp2.detach().numpy()\n",
    "    temp1 = temp1.numpy()\n",
    "    ans = 20*np.log10(np.linalg.norm(temp1, ord=2)/np.linalg.norm(temp2, ord=2))\n",
    "    return ans\n",
    "def loss_function(AdvTensor, TarTensor,noise_tensor):\n",
    "    return torch.norm(AdvTensor - TarTensor) + 0.5 *  torch.norm(noise_tensor, float('inf'))\n",
    "\n",
    "def trans_wav_mp3(file_path):\n",
    "    \"\"\"\n",
    "    将wav文件转为mp3文件，保存到cmu_mp3\n",
    "    \"\"\"\n",
    "    sourcefile = AudioSegment.from_wav(file_path)\n",
    "    #filename = file_path.split('/')[-1].split('.wav')[0].replace(' ', '_') + '.mp3'\n",
    "    filename = file_path.split('/')[-1].split('.wav')[0] + '.mp3'\n",
    "    save_path = \"/mnt/data/dvector/adv_sample/mp3/\"\n",
    "    #print(filename)\n",
    "    sourcefile.export(save_path + filename, format=\"mp3\")\n",
    "\n",
    "###unisound\n",
    "# def getSign(timestamp, nonce):\n",
    "#     hs = hashlib.sha256()\n",
    "#     appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "#     secret = '3c8a61e2bdb0ee2d0af74814142ba2ee'\n",
    "#     hs.update((appkey + timestamp + secret + nonce).encode('utf-8'))\n",
    "#     signature = hs.hexdigest().upper()\n",
    "#     return signature\n",
    "# def identifyFeatureByGroupId(confirmFeatureFileName):\n",
    "#     identify_feature = open(confirmFeatureFileName, 'rb').read()\n",
    "#     # 声纹base64字符串\n",
    "#     audio_data = base64.b64encode(identify_feature)\n",
    "#     timestamp = str(int(time.time() * 1000))\n",
    "#     nonce = str(uuid.uuid1()).replace('-', '')\n",
    "#     sign = getSign(timestamp, nonce)\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "#     groupId = '15'\n",
    "#     host = 'https://ai-vpr.hivoice.cn'\n",
    "#     identifyFeatureByGroupIdEndPoint = '/vpr/v1/identifyFeatureByGroupId'\n",
    "#     identify_feature_param = {\n",
    "#         \"appkey\": appkey,\n",
    "#         \"timestamp\": timestamp,\n",
    "#         \"nonce\": nonce,\n",
    "#         \"sign\": sign,\n",
    "#         \"groupId\": groupId,\n",
    "#         \"topN\": 10,\n",
    "#         \"audioData\": audio_data.decode(),\n",
    "#         \"audioSampleRate\": 16000,\n",
    "#         \"audioFormat\": \"wav\"\n",
    "#     }\n",
    "#     #print('identify_feature_param', identify_feature_param)\n",
    "#     identify_feature_resp = requests.post(url=host + identifyFeatureByGroupIdEndPoint,\n",
    "#                                           data=json.dumps(identify_feature_param),\n",
    "#                                           headers=headers)\n",
    "#     identify_feature_result = json.loads(identify_feature_resp.content)\n",
    "#     return identify_feature_result['data'][0]['featureInfo'], identify_feature_result['data'][0]['score'],identify_feature_result['data'][1]['featureInfo'], identify_feature_result['data'][1]['score']\n",
    "# for param in wav2mel.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in dvector.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/mnt/data/Chenpinji/cmu_dataset/cmu1/wav/arctic_a0040.wav\n",
      "epoch=0 loss=209.26116943359375\n",
      "SNR: 21.085121631622314\n",
      "cmu1\n",
      "0.896\n",
      "epoch=100 loss=226.4617919921875\n",
      "SNR: 21.02619171142578\n",
      "cmu1\n",
      "0.884\n",
      "epoch=200 loss=234.1457061767578\n",
      "SNR: 21.00250482559204\n",
      "cmu1\n",
      "0.867\n",
      "epoch=300 loss=238.69163513183594\n",
      "SNR: 20.981528759002686\n",
      "cmu1\n",
      "0.859\n",
      "epoch=400 loss=248.03038024902344\n",
      "SNR: 20.95553159713745\n",
      "cmu1\n",
      "0.845\n",
      "epoch=500 loss=243.09991455078125\n",
      "SNR: 20.94470977783203\n",
      "cmu1\n",
      "0.847\n",
      "epoch=600 loss=241.98477172851562\n",
      "SNR: 20.938262939453125\n",
      "cmu1\n",
      "0.847\n",
      "epoch=700 loss=240.70083618164062\n",
      "SNR: 20.93198299407959\n",
      "cmu1\n",
      "0.849\n",
      "epoch=800 loss=242.0277557373047\n",
      "SNR: 20.93024969100952\n",
      "cmu1\n",
      "0.848\n",
      "epoch=900 loss=239.46612548828125\n",
      "SNR: 20.93231439590454\n",
      "cmu1\n",
      "0.846\n",
      "epoch=1000 loss=239.42919921875\n",
      "SNR: 20.93621253967285\n",
      "cmu1\n",
      "0.85\n",
      "epoch=1100 loss=240.00909423828125\n",
      "SNR: 20.934879779815674\n",
      "cmu1\n",
      "0.852\n",
      "epoch=1200 loss=241.60867309570312\n",
      "SNR: 20.93437910079956\n",
      "cmu1\n",
      "0.85\n",
      "epoch=1300 loss=240.91111755371094\n",
      "SNR: 20.935182571411133\n",
      "cmu1\n",
      "0.843\n",
      "epoch=1400 loss=238.91510009765625\n",
      "SNR: 20.941715240478516\n",
      "cmu1\n",
      "0.842\n",
      "epoch=1500 loss=237.65768432617188\n",
      "SNR: 20.94949722290039\n",
      "cmu1\n",
      "0.838\n",
      "epoch=1600 loss=236.3979949951172\n",
      "SNR: 20.956051349639893\n",
      "cmu1\n",
      "0.838\n",
      "epoch=1700 loss=236.12405395507812\n",
      "SNR: 20.963170528411865\n",
      "cmu1\n",
      "0.839\n",
      "epoch=1800 loss=235.6730499267578\n",
      "SNR: 20.970795154571533\n",
      "cmu1\n",
      "0.837\n",
      "epoch=1900 loss=235.13734436035156\n",
      "SNR: 20.979857444763184\n",
      "cmu1\n",
      "0.831\n",
      "epoch=2000 loss=235.0231170654297\n",
      "SNR: 20.988173484802246\n",
      "cmu1\n",
      "0.833\n",
      "epoch=2100 loss=232.91806030273438\n",
      "SNR: 20.998096466064453\n",
      "cmu1\n",
      "0.834\n",
      "epoch=2200 loss=231.8366241455078\n",
      "SNR: 21.00731134414673\n",
      "cmu1\n",
      "0.836\n",
      "epoch=2300 loss=230.98486328125\n",
      "SNR: 21.017167568206787\n",
      "cmu1\n",
      "0.836\n",
      "epoch=2400 loss=229.789306640625\n",
      "SNR: 21.02757692337036\n",
      "cmu1\n",
      "0.833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ed0e1d96a180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#print(TarTensor.grad_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvector_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_tensor1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdvector_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_tensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "persons = ['cmu1','cmu2','cmu6','cmu4','cmu5','cmu_canadian','cmu7','cmu_indian','cmu_scottish'] #'1','2','3','4','5','6','7','_canadian','_indian','_scottish'\n",
    "ofiles = ['0005'] #'0002', '0093', '0090', '0100', '0133'\n",
    "for person in persons:\n",
    "    for ofile in ofiles:\n",
    "    #for i in range(40,48):\n",
    "        #owavname = 'arctic_a'+format(i, '04d')+'.wav'\n",
    "        #owavname = ofile +'.wav'\n",
    "        #filename1 = \"/mnt/data/voxData/wav/\" + person + owavname\n",
    "        owavname = ofile +'.wav'\n",
    "        filename1 = '/mnt/data/Chenpinji/cmu_dataset/'+ person+ '/wav/'+ owavname\n",
    "        print()\n",
    "        print(filename1)\n",
    "        #filename2 = '/mnt/data/voxData/wav/id10951/79QBzxH-aOw/00003.wav'\n",
    "        filename2 = '/mnt/data/Chenpinji/cmu_dataset/cmu3/wav/arctic_a0008.wav'\n",
    "        wav_tensor1, sample_rate1 = torchaudio.load(filename1, normalize=False)\n",
    "        wav_tensor2, sample_rate2 = torchaudio.load(filename2, normalize=False)\n",
    "        noise_tensor = torch.normal(mean = 300., std = 30.,size = (1, len(wav_tensor1[0])))\n",
    "        wav_tensor1 = wav_tensor1[0].to(torch.float)\n",
    "        wav_tensor2 = wav_tensor2[0].to(torch.float)\n",
    "        noise_tensor = noise_tensor[0].to(torch.float)\n",
    "        #noise_tensor = noise_tensor.cuda()\n",
    "        noise_tensor.requires_grad = True\n",
    "        optimizer = torch.optim.Adam([noise_tensor],lr = 3)\n",
    "        epochs = 4000\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            # AdvTensor = dvector_extraction(wav_tensor1) + dvector_extraction(wav_tensor2)\n",
    "            # TarTensor = dvector_extraction(noise_tensor)\n",
    "            #print(TarTensor.grad_fn)\n",
    "            loss = loss_function(dvector_extraction(wav_tensor1 + noise_tensor), dvector_extraction(wav_tensor2), noise_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "                print(\"epoch={} loss={}\".format(epoch, loss))\n",
    "                print(\"SNR:\",SNR(wav_tensor1, noise_tensor))\n",
    "                oname = 'dvectorGen_'+ str(epoch)\n",
    "                audio_name = '/mnt/data/dvector/adv_sample/'+'dvectorGen_'+str(epoch)+'.wav'\n",
    "                temp = wav_tensor1 + noise_tensor\n",
    "                temp = temp.detach().numpy()\n",
    "                scaled = np.array(np.clip(np.round(temp),-2 ** 15, 2 ** 15 - 1), dtype = np.int16)\n",
    "                wf.write(audio_name, 16000 ,scaled)\n",
    "                asperson, s = talentedsoft.talent_score(audio_name,'cmu3')\n",
    "                print(asperson)\n",
    "                print(s)\n",
    "                #trans_wav_mp3(audio_name)\n",
    "                #value = req_score(api_name='searchFea', APPId=APPId,APIKey=APIKey, APISecret=APISecret, file_path='/mnt/data/dvector/adv_sample/mp3/'+ oname + '.mp3')\n",
    "                #speaker1,score1,speaker2,score2 = GetSpeakerScore('cmu7',value)\n",
    "                # speaker1,score1,speaker2,score2 = identifyFeatureByGroupId(audio_name)\n",
    "                #print('classified as:',speaker1,'Score is:',score1)\n",
    "                #print('second place is:',speaker2, 'Score is:',score2)\n",
    "                \n",
    "    \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be6795e88697a9790b6af751dbe32447fc9259a59c897c8a604ee8792f1ea307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
