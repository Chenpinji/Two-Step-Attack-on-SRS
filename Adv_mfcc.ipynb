{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import wave as wav\n",
    "import os\n",
    "import librosa\n",
    "import soundfile\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "import tensorflow as tf\n",
    "import generate_masking_threshold as generate_mask\n",
    "import base64\n",
    "import hashlib\n",
    "import json \n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import scipy\n",
    "import random\n",
    "import talentedsoft\n",
    "#import scikits.audiolab\n",
    "\n",
    "def compute_mfcc(audio, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the MFCC for a given audio waveform. This is\n",
    "    identical to how DeepSpeech does it, but does it all in\n",
    "    TensorFlow so that we can differentiate through it.\n",
    "    \"\"\"\n",
    "    batch_size, size = audio.get_shape().as_list()\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "\n",
    "    # 1. Pre-emphasizer, a high-pass filter\n",
    "    audio = tf.concat(\n",
    "        (audio[:, :1], audio[:, 1:] - 0.97 * audio[:, :-1], np.zeros((batch_size, 512), dtype=np.float32)), 1)\n",
    "\n",
    "    # 2. windowing into frames of 512 samples, overlapping\n",
    "    windowed = tf.stack([audio[:, i:i + 512] for i in range(0, size - 320, 320)], 1)\n",
    "\n",
    "    window = np.hamming(512)\n",
    "    windowed = windowed * window\n",
    "\n",
    "    # 3. Take the FFT to convert to frequency space\n",
    "    ffted = tf.spectral.rfft(windowed, [512])\n",
    "    ffted = 1.0 / 512 * tf.square(tf.abs(ffted))\n",
    "\n",
    "    # 4. Compute the Mel windowing of the FFT\n",
    "    energy = tf.reduce_sum(ffted, axis=2) + np.finfo(float).eps\n",
    "    filters = np.load(\"filterbanks.npy\").T\n",
    "    feat = tf.matmul(ffted, np.array([filters] * batch_size, dtype=np.float32)) + np.finfo(float).eps\n",
    "\n",
    "    # 5. Take the DCT again, because why not\n",
    "    feat = tf.log(feat)\n",
    "    feat = tf.spectral.dct(feat, type=2, norm='ortho')[:, :, :26]\n",
    "\n",
    "    # 6. Amplify high frequencies for some reason\n",
    "    _, nframes, ncoeff = feat.get_shape().as_list()\n",
    "    n = np.arange(ncoeff)\n",
    "    lift = 1 + (22 / 2.) * np.sin(np.pi * n / 22)\n",
    "    feat = lift * feat\n",
    "    width = feat.get_shape().as_list()[1]\n",
    "\n",
    "    # 7. And now stick the energy next to the features\n",
    "    feat = tf.concat((tf.reshape(tf.log(energy), (-1, width, 1)), feat[:, :, 1:]), axis=2)\n",
    "    return feat\n",
    "\n",
    "def pad(mfcc2,mfcc1):\n",
    "    size1 = mfcc1.get_shape().as_list()\n",
    "    size2 = mfcc2.get_shape().as_list()\n",
    "    length = size1[1] - size2[1]\n",
    "    paddings = [[0,0],[0,length],[0,0]]\n",
    "    return tf.pad(mfcc2,paddings,\"CONSTANT\")\n",
    "\n",
    "def SNR(origanl, current):\n",
    "    noise=current-origanl\n",
    "    origanl_ar = sess.run(origanl)\n",
    "    noise_ar = sess.run(noise)\n",
    "    ans = 20*np.log10(np.linalg.norm(origanl_ar, ord=2)/np.linalg.norm(noise_ar, ord=2))\n",
    "    return ans\n",
    "\n",
    "def new_input(noise, audio_sequence1):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tensor = tf.clip_by_value(noise+audio_sequence1, -2**15, 2**15-1)\n",
    "        array = sess.run(tensor)\n",
    "    return array\n",
    "\n",
    "def psychoacoustic_loss(adv_audio, original, psd_max_a, th,transform):\n",
    "    logits_delta = transform((adv_audio[0,:] - original[0,:]),psd_max_a[0])\n",
    "    psychoacoustic_loss = tf.reduce_mean(tf.nn.relu(logits_delta - th[0]))\n",
    "    return psychoacoustic_loss\n",
    "\n",
    "def truncate(mfcc1, mfcc2):\n",
    "    size1 = mfcc1.get_shape().as_list()#origin\n",
    "    #size2 = mfcc2.get_shape().as_list()#target\n",
    "    mfcc2 = tf.slice(mfcc2,[0,0,0],[1,size1[1],26])\n",
    "    return mfcc2\n",
    "\n",
    "def loss(original, target, noise, psychoacoustic_loss,alpha):\n",
    "    mfcc1 = compute_mfcc(original + noise)\n",
    "    size1 = original.get_shape().as_list()\n",
    "    size2 = target.get_shape().as_list()\n",
    "    if size1[1] > size2[1]:\n",
    "        mfcc2 = pad(compute_mfcc(target),mfcc1)\n",
    "    else:\n",
    "        mfcc2 = truncate(mfcc1,compute_mfcc(target))\n",
    "    loss = tf.norm(mfcc1-mfcc2,2) + alpha * psychoacoustic_loss\n",
    "    #+ 0.01 * tf.cast(tf.norm(noise,2),dtype = tf.float32)\n",
    "#     loss =  tf.norm(cal_mfcc(new_input(noise, audio_sequence1),sample_rate1) \n",
    "#     - pad(cal_mfcc(audio_sequence2, sample_rate2)),2) + 0.001 * tf.cast(tf.norm(noise, 2),dtype = tf.float64)\n",
    "    return loss\n",
    "APPId = \"fcfefe42\"\n",
    "APISecret = \"NmE5NTZkNzFlMzg3MGM0ZDBmZTdkODYx\"\n",
    "APIKey = \"aba4d1c2815577b411d5d5a4966796aa\"\n",
    "class Gen_req_url(object):\n",
    "    \"\"\"生成请求的url\"\"\"\n",
    "\n",
    "    def sha256base64(self, data):\n",
    "        sha256 = hashlib.sha256()\n",
    "        sha256.update(data)\n",
    "        digest = base64.b64encode(sha256.digest()).decode(encoding='utf-8')\n",
    "        return digest\n",
    "\n",
    "    def parse_url(self, requset_url):\n",
    "        stidx = requset_url.index(\"://\")\n",
    "        host = requset_url[stidx + 3:]\n",
    "        # self.schema = requset_url[:stidx + 3]\n",
    "        edidx = host.index(\"/\")\n",
    "        if edidx <= 0:\n",
    "            raise Exception(\"invalid request url:\" + requset_url)\n",
    "        self.path = host[edidx:]\n",
    "        self.host = host[:edidx]\n",
    "\n",
    "    # build websocket auth request url\n",
    "    def assemble_ws_auth_url(self, requset_url, api_key, api_secret, method=\"GET\"):\n",
    "        self.parse_url(requset_url)\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "        # date = \"Thu, 12 Dec 2019 01:57:27 GMT\"\n",
    "        signature_origin = \"host: {}\\ndate: {}\\n{} {} HTTP/1.1\".format(self.host, date, method, self.path)\n",
    "        signature_sha = hmac.new(api_secret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "        signature_sha = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "        authorization_origin = \"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\" % (\n",
    "            api_key, \"hmac-sha256\", \"host date request-line\", signature_sha)\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "        values = {\n",
    "            \"host\": self.host,\n",
    "            \"date\": date,\n",
    "            \"authorization\": authorization\n",
    "        }\n",
    "\n",
    "        return requset_url + \"?\" + urlencode(values)\n",
    "\n",
    "\n",
    "def gen_req_body(apiname, APPId, file_path=None):\n",
    "    \"\"\"\n",
    "    生成请求的body\n",
    "    :param apiname\n",
    "    :param APPId: Appid\n",
    "    :param file_name:  文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if apiname == 'createFeature':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"createFeature\",\n",
    "                    \"groupId\": \"8\",\n",
    "                    \"featureId\": \"cmu_scottish\",\n",
    "                    \"featureInfo\": \"wav08\",\n",
    "                    \"createFeatureRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'createGroup':\n",
    "\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"createGroup\",\n",
    "                    \"groupId\": \"8\",\n",
    "                    \"groupName\": \"cmu_dataset\",\n",
    "                    \"groupInfo\": \"cmu_dataset\",\n",
    "                    \"createGroupRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "   \n",
    "    elif apiname == 'queryFeatureList':\n",
    "\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"queryFeatureList\",\n",
    "                    \"groupId\": \"8\",\n",
    "                    \"queryFeatureListRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'searchFea':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"searchFea\",\n",
    "                    \"groupId\": \"8\",\n",
    "                    \"topK\": 10,\n",
    "                    \"searchFeaRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    elif apiname == 'searchScoreFea':\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            audioBytes = f.read()\n",
    "        body = {\n",
    "            \"header\": {\n",
    "                \"app_id\": APPId,\n",
    "                \"status\": 3\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s782b4996\": {\n",
    "                    \"func\": \"searchScoreFea\",\n",
    "                    \"groupId\": \"iFLYTEK_examples_groupId\",\n",
    "                    \"dstFeatureId\": \"p374\",\n",
    "                    \"searchScoreFeaRes\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"resource\": {\n",
    "                    \"encoding\": \"lame\",\n",
    "                    \"sample_rate\": 16000,\n",
    "                    \"channels\": 1,\n",
    "                    \"bit_depth\": 16,\n",
    "                    \"status\": 3,\n",
    "                    \"audio\": str(base64.b64encode(audioBytes), 'UTF-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"输入的apiname不在[createFeature, createGroup, deleteFeature, queryFeatureList, searchFea, searchScoreFea,updateFeature]内，请检查\")\n",
    "    return body\n",
    "\n",
    "def req_url(api_name, APPId, APIKey, APISecret, file_path=None):\n",
    "    \"\"\"\n",
    "    开始请求\n",
    "    :param APPId: APPID\n",
    "    :param APIKey:  APIKEY\n",
    "    :param APISecret: APISecret\n",
    "    :param file_path: body里的文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gen_req_url = Gen_req_url()\n",
    "    body = gen_req_body(apiname=api_name, APPId=APPId, file_path=file_path)\n",
    "    request_url = gen_req_url.assemble_ws_auth_url(requset_url='https://api.xf-yun.com/v1/private/s782b4996', method=\"POST\", api_key=APIKey, api_secret=APISecret)\n",
    "    headers = {'content-type': \"application/json\", 'host': 'api.xf-yun.com', 'appid': '$APPID'}\n",
    "    response = requests.post(request_url, data=json.dumps(body), headers=headers)\n",
    "    tempResult = json.loads(response.content.decode('utf-8'))\n",
    "    #print(tempResult)\n",
    "    #print(base64.b64decode(tempResult['payload'][api_name + 'Res']['text']))\n",
    "\"\"\"\n",
    " * 1.声纹识别接口,请填写在讯飞开放平台-控制台-对应能力页面获取的APPID、APIKey、APISecret\n",
    " * 2.groupId要先创建,然后再在createFeature里使用,不然会报错23005,修改时需要注意保持统一\n",
    " * 3.音频base64编码后数据(不超过4M),音频格式需要16K、16BIT的MP3音频。\n",
    " * 4.主函数只提供调用示例,其他参数请到对应类去更改,以适应实际的应用场景。\n",
    "\"\"\"\n",
    "def req_score(api_name, APPId,  APIKey, APISecret, file_path=None):\n",
    "    gen_req_url = Gen_req_url()\n",
    "    body = gen_req_body(apiname=api_name, APPId=APPId, file_path=file_path)\n",
    "    request_url = gen_req_url.assemble_ws_auth_url(requset_url='https://api.xf-yun.com/v1/private/s782b4996', method=\"POST\", api_key=APIKey, api_secret=APISecret)\n",
    "    headers = {'content-type': \"application/json\", 'host': 'api.xf-yun.com', 'appid': '$APPID'}\n",
    "    response = requests.post(request_url, data=json.dumps(body), headers=headers)\n",
    "    tempResult = json.loads(response.content.decode('utf-8'))\n",
    "    #print(tempResult)\n",
    "    return base64.b64decode(tempResult['payload'][api_name + 'Res']['text'])#,base64.b64decode(tempResult['payload'][api_name + 'Res']['text']['scoreList'][0]['score'])\n",
    "\n",
    "\n",
    "def GetSpeakerScore(speaker,value):\n",
    "    m = len(value)\n",
    "    result = ''\n",
    "    for i in range(0,m):\n",
    "        result+=chr(value[i]) #switch to string\n",
    "    result = eval(result)\n",
    "    v = list(result.values())[0]\n",
    "    #print(v)\n",
    "    lenv=len(v)\n",
    "    return v[0]['featureId'], v[0]['score'], v[1]['featureId'],v[1]['score']    \n",
    "# def getSign(timestamp, nonce):\n",
    "#     hs = hashlib.sha256()\n",
    "#     appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "#     secret = '3c8a61e2bdb0ee2d0af74814142ba2ee'\n",
    "#     hs.update((appkey + timestamp + secret + nonce).encode('utf-8'))\n",
    "#     signature = hs.hexdigest().upper()\n",
    "#     return signature\n",
    "# def identifyFeatureByGroupId(confirmFeatureFileName):\n",
    "#     identify_feature = open(confirmFeatureFileName, 'rb').read()\n",
    "#     # 声纹base64字符串\n",
    "#     audio_data = base64.b64encode(identify_feature)\n",
    "#     timestamp = str(int(time.time() * 1000))\n",
    "#     nonce = str(uuid.uuid1()).replace('-', '')\n",
    "#     sign = getSign(timestamp, nonce)\n",
    "#     headers = {\"Content-Type\": \"application/json\"}\n",
    "#     appkey = \"zvpcvm5hxib3jz3vt2jshqxjndcywwo2qnx7s6iy\"\n",
    "#     groupId = '15'\n",
    "#     host = 'https://ai-vpr.hivoice.cn'\n",
    "#     identifyFeatureByGroupIdEndPoint = '/vpr/v1/identifyFeatureByGroupId'\n",
    "#     identify_feature_param = {\n",
    "#         \"appkey\": appkey,\n",
    "#         \"timestamp\": timestamp,\n",
    "#         \"nonce\": nonce,\n",
    "#         \"sign\": sign,\n",
    "#         \"groupId\": groupId,\n",
    "#         \"topN\": 6,\n",
    "#         \"audioData\": audio_data.decode(),\n",
    "#         \"audioSampleRate\": 16000,\n",
    "#         \"audioFormat\": \"wav\"\n",
    "#     }\n",
    "#     #print('identify_feature_param', identify_feature_param)\n",
    "#     identify_feature_resp = requests.post(url=host + identifyFeatureByGroupIdEndPoint,\n",
    "#                                           data=json.dumps(identify_feature_param),\n",
    "#                                           headers=headers)\n",
    "#     identify_feature_result = json.loads(identify_feature_resp.content)\n",
    "#     return identify_feature_result['data'][0]['featureInfo'], identify_feature_result['data'][0]['score'],identify_feature_result['data'][1]['featureInfo'], identify_feature_result['data'][1]['score']\n",
    "def trans_wav_mp3(file_path):\n",
    "    \"\"\"\n",
    "    将wav文件转为mp3文件，保存到cmu_mp3\n",
    "    \"\"\"\n",
    "    sourcefile = AudioSegment.from_wav(file_path)\n",
    "    #filename = file_path.split('/')[-1].split('.wav')[0].replace(' ', '_') + '.mp3'\n",
    "    filename = file_path.split('/')[-1].split('.wav')[0] + '.mp3'\n",
    "    save_path = \"/mnt/data/Chenpinji/mfcc_advGen/mp3/\"\n",
    "    #print(filename)\n",
    "    sourcefile.export(save_path + filename, format=\"mp3\")\n",
    "\n",
    "class Transform(object):\n",
    "    '''\n",
    "    Return: PSD\n",
    "    '''\n",
    "    def __init__(self, window_size):\n",
    "        self.scale = 8. / 3.\n",
    "        self.frame_length = int(window_size)\n",
    "        self.frame_step = int(window_size // 4)\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __call__(self, x, psd_max_ori):\n",
    "        win = tf.contrib.signal.stft(x, self.frame_length, self.frame_step)\n",
    "        z = self.scale * tf.abs(win / self.window_size)\n",
    "        psd = tf.square(z)\n",
    "        PSD = tf.pow(10., 9.6) / tf.reshape(psd_max_ori, [-1, 1, 1]) * psd\n",
    "        return PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "current loss: 1016.82965 SNR: 34.31811332702637\n",
      "current psychoacoustic_loss 1588.2177\n",
      "classified as: cmu1 Score is: 0.985\n",
      "100\n",
      "current loss: 747.7936 SNR: 27.695353031158447\n",
      "current psychoacoustic_loss 9464.327\n",
      "classified as: cmu1 Score is: 0.943\n",
      "200\n",
      "current loss: 678.8578 SNR: 23.566372394561768\n",
      "current psychoacoustic_loss 26116.97\n",
      "classified as: cmu1 Score is: 0.78\n",
      "300\n",
      "current loss: 647.3849 SNR: 20.9637451171875\n",
      "current psychoacoustic_loss 48965.668\n",
      "classified as: cmu1 Score is: 0.529\n",
      "400\n",
      "current loss: 633.7998 SNR: 19.069232940673828\n",
      "current psychoacoustic_loss 76691.53\n",
      "classified as: cmu1 Score is: 0.298\n",
      "500\n",
      "current loss: 632.40515 SNR: 17.59600043296814\n",
      "current psychoacoustic_loss 108270.305\n",
      "classified as: cmu2 Score is: 0.178\n",
      "600\n",
      "current loss: 640.3434 SNR: 16.395325660705566\n",
      "current psychoacoustic_loss 143002.22\n",
      "classified as: cmu2 Score is: 0.203\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bd90f665b73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_teacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mselect3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNewInput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsychoacoustic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsd_max_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsychoacoustic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsd_max_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSNR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNewInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "filename1 = '/mnt/data/Chenpinji/cmu_dataset/cmu1/wav/arctic_a0006.wav'\n",
    "filename2 = '/mnt/data/Chenpinji/cmu_dataset/cmu2/wav/arctic_a0008.wav'\n",
    "sample_rate1, audio_sequence1 = wf.read(filename1)\n",
    "sample_rate2, audio_sequence2 = wf.read(filename2)\n",
    "#time = a1 / f1#音频时长\n",
    "audio1 = np.expand_dims(audio_sequence1,0)\n",
    "audio2 = np.expand_dims(audio_sequence2,0)\n",
    "len1 = len(audio1[0])\n",
    "len2 = len(audio2[0])\n",
    "th, psd_max = generate_mask.generate_th(audio_sequence1.astype(float), 16000, 2048)\n",
    "th=np.expand_dims(th,0)\n",
    "psd_max=np.expand_dims(psd_max,0)\n",
    "transform = Transform(2048)\n",
    "psd_max_a = tf.cast(psd_max, tf.float32)\n",
    "\n",
    "#stage 1, nearly no constraint on noise size, which aims to make the attack succeed\n",
    "original = tf.Variable(np.zeros((1, len1), dtype=np.float32))\n",
    "target  = tf.Variable(np.zeros((1, len2), dtype=np.float32))\n",
    "with tf.variable_scope(\"noise\"):\n",
    "    noise=tf.Variable(tf.random_normal([1,len1],stddev = 50))\n",
    "    #noise=tf.clip_by_value(noise,-5000,5000)\n",
    "    t_vars = tf.trainable_variables()\n",
    "    noise_vars = [var for var in t_vars if \"noise\" in var.name]\n",
    "#config = tf.ConfigProto(device_count = {'CPU': 4})\n",
    "with tf.Session() as sess:\n",
    "    train_teacher = tf.train.AdamOptimizer(2).minimize (loss(original, target, noise, psychoacoustic_loss(original + noise, original, psd_max_a, th,transform),0.00001), var_list=noise_vars)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    original = original.assign(np.array(audio1))\n",
    "    target   = target.assign(np.array(audio2))\n",
    "    select3 = 2000\n",
    "    for i in range(select3):\n",
    "        sess.run((train_teacher))\n",
    "        if i % 100 == 0 or i == select3 - 1:\n",
    "            a,b,NewInput= sess.run([loss(original, target, noise, psychoacoustic_loss(original + noise, original, psd_max_a, th,transform), 0.001),psychoacoustic_loss(original + noise, original, psd_max_a, th,transform), original + noise])\n",
    "            print(i)\n",
    "            snr = SNR(original, NewInput)\n",
    "            print('current loss:',a,'SNR:',snr)\n",
    "            print('current psychoacoustic_loss', b)\n",
    "            oname = 'cmu1_cmu2_'+str(snr)\n",
    "            audio_name = '/mnt/data/Chenpinji/mfcc_advGen/'+ oname + '.wav'\n",
    "            scaled = np.array(np.clip(np.round(NewInput[0]),-2 ** 15, 2 ** 15 - 1),dtype = np.int16)\n",
    "            wf.write(audio_name, 16000 ,scaled)\n",
    "            #trans_wav_mp3(audio_name)\n",
    "            #value = req_score(api_name='searchFea', APPId=APPId,APIKey=APIKey, APISecret=APISecret, file_path='/mnt/data/Chenpinji/adv_mfccGen/mp3'+ oname + '.mp3')\n",
    "            #speaker1,score1,speaker2,score2 = GetSpeakerScore('cmu7',value)\n",
    "            asperson, s = talentedsoft.talent_score(audio_name,'cmu7')\n",
    "            print('classified as:',asperson,'Score is:',s)\n",
    "            #print('second place is:',speaker2, 'Score is:',score2)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be6795e88697a9790b6af751dbe32447fc9259a59c897c8a604ee8792f1ea307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
